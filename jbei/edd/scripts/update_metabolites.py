# -*- coding: utf-8 -*-
from __future__ import unicode_literals

import json
import logging
import os
import re

from openpyxl.utils.cell import get_column_letter

logging.basicConfig(level='INFO')
logger = logging.getLogger(__name__)

# identifiers from the MetaNetX file
COMMENT_PATTERN = re.compile('^\s*#.*$')
XREF_FILE_HEADER = 'Xrefs'

# identifiers used in Tyler's JSON file with scraped results
PUBCHEM_ID = 'pubChemCid'


def _load_scraped_metabolite_json():
    """
    Loads the output file from Tyler's script
    :return:
    """
    metabolite_file = os.path.join(os.path.dirname(__file__), 'eddMetabolites.json')
    with open(metabolite_file, 'r') as f:
        return json.load(f)


def load_mnx_cross_reference_file():
    """
        Parses a metabolite mapping file generated by MetaNetX and builds a list of mappings
        from BIGG identifiers to PubChem identifiers
    """
    reference_file = os.path.join(os.path.dirname(__file__), 'bigg_pubchem_xref.tsv')

    bigg_to_pubchem = {}
    multiple_mappings_count = 0

    with open(reference_file, 'r') as f:

        cross_ref_col = None

        line_num = 0
        for line in f:
            line_num += 1
            # if line contains the expected header, grab column definitions
            if line.startswith('#MNX_reference_ID'):
                column_headers = line.split('\t')

                for index, header in enumerate(column_headers):
                    if XREF_FILE_HEADER == header.strip():
                        cross_ref_col = index
                        logger.info('Found MetaNetX cross reference column (index %(index)d or '
                                    'letter %(letter)s' % {
                                        'index': cross_ref_col,
                                        'letter': get_column_letter(cross_ref_col + 1), })
                        break

                else:
                    continue

            if COMMENT_PATTERN.match(line):
                continue

            if cross_ref_col is None:
                raise RuntimeError('Unable to find required column label "%s".' % XREF_FILE_HEADER)

            tokens = line.split('\t')

            if len(tokens) <= cross_ref_col:
                logger.warning("Skipped row %s (too few columns)" % line_num)
                continue

            cross_references = tokens[cross_ref_col].split(';')

            bigg_ids = []
            pubchem_ids = []

            # loop over cross references, building lists of BIGG and Uniprot ID's that we can use
            # to generate mappings after they're all parsed
            for reference in cross_references:
                parts = reference.split(':')

                if len(parts) != 2:
                    logger.debug('Skipped non-delimited reference "%(ref)s on line %(line)d"' % {
                        'ref': reference,
                        'line': line_num,
                    })
                    continue

                source = parts[0]
                id = parts[1]

                if source.startswith('bigg'):
                    bigg_ids.append(id)
                elif source.startswith('pubchem'):
                    pubchem_ids.append(id)
                else:
                    logger.debug('Skipping irrelevant source "%s"' % source)
                    continue

            # after parsing all the ID's, build the mapping so that each BIGG ID maps to all the
            # associated pubchem ID's
            if len(pubchem_ids) > 1:
                multiple_mappings_count += 1

            if bigg_ids and pubchem_ids:
                for bigg_id in bigg_ids:
                    bigg_to_pubchem[bigg_id] = pubchem_ids

    if bigg_to_pubchem:
        logger.info('Found %d MetanetX entries that map one or more BIGG ids '
                    'to PubChem ids' % len(bigg_to_pubchem))

    if multiple_mappings_count:
        logger.warning('Found %d MetanetX entries with multiple pubchem mappings' %
                       multiple_mappings_count)

    return bigg_to_pubchem


RESULT_FORMAT = """\
Results:
    Matching pubchem IDs: %(matching)d
    Confirmed pubchem IDs: %(confirmed)d
    Added pubchem IDs: %(added)d
    Added arbitrarily: %(added_arbitrary)d
    Conflicted: %(conflicted)d
    Unmatched BIGG ids: %(unmatched)d
"""


class Results:
    def __init__(self):
        self._matching_pubchem_ids = 0
        self._confirmed_pubchem_ids = 0
        self._added_pubchem_ids = 0
        self._conflicted_pubchem_ids = 0
        self._added_pubchem_ids = 0
        self._added_arbitrary_pubchem_ids = 0
        self._unmatched_bigg_ids = 0

    def matched_pubchem_id(self, bigg, scraped, metanetx):
        self._matching_pubchem_ids += 1

    def conflicted_pubchem_id(self, bigg, scraped, metanetx):
        self._conflicted_pubchem_ids += 1

    def confirmed_pubchem_id(self, bigg, scraped, metanetx):
        self._confirmed_pubchem_ids += 1

    def added_pubchem_id(self, bigg, metanetx):
        self._added_pubchem_ids += 1
        logger.info('Added relationship from BIGG ID %(bigg)s to PubChem ID %(pubchem)s' % {
            'bigg': bigg,
            'pubchem': metanetx,
        })

    def added_arbirtrary_id(self, bigg, added, mnx_pubchem_ids):
        self._added_arbitrary_pubchem_ids += 1
        logger.info('Added arbitrary relationship from BIGG ID %(bigg)s to PubChem ID '
                    '%(arb_pubchem)s. Full set of PubChem IDs was: %(all_pubchem)s' % {
                        'bigg': bigg,
                        'arb_pubchem': added,
                        'all_pubchem': ','.join(mnx_pubchem_ids)
        })

    def unmatched_bigg_id(self, bigg):
        self._unmatched_bigg_ids += 1

    def log(self):
        logger.info(RESULT_FORMAT % {
            'matching': self._matching_pubchem_ids,
            'confirmed': self._confirmed_pubchem_ids,
            'added': self._added_pubchem_ids,
            'added_arbitrary': self._added_arbitrary_pubchem_ids,
            'conflicted': self._conflicted_pubchem_ids,
            'unmatched': self._unmatched_bigg_ids,
        })


def main():
    # load datafiles from Tyler's scraped data and from MetaNetX mappings
    bigg_to_pubchem_mappings = load_mnx_cross_reference_file()
    logger.info('Read %d mappings from MetaNetX file that contained one or more BIGG references '
                'and at least one PubChem reference'
                % len(bigg_to_pubchem_mappings))
    metabolites = _load_scraped_metabolite_json()

    logger.info('Read %d metabolites from scraped data file' % len(metabolites))

    results = Results()

    # iterate over scraped big -> pubchem links, using MetaNetNX to confirm or fill gaps in that
    #  data.  Note that this doesn't cover any existing EDD metabolites that may be resolvable
    # using the MetaNetNX data
    for metabolite in metabolites.itervalues():
        scraped_id_links = metabolite['identifierLinks']
        scraped_bigg_ids = scraped_id_links.get('universal_bigg_id', None)

        # skip any metabolites we don't have a BIGG ID for
        if not scraped_bigg_ids:
            continue

        scraped_pubchem_ids = scraped_id_links.get(PUBCHEM_ID, None)
        scraped_pubchem_id = None
        if scraped_pubchem_ids:
            if len(scraped_pubchem_ids) > 1:
                raise Exception('Multiple scraped pubchem IDs are not supported')
            scraped_pubchem_id = scraped_pubchem_ids[0]

        for bigg_id in scraped_bigg_ids:
            mnx_pubchem_ids = bigg_to_pubchem_mappings.get(bigg_id, None)

            if not mnx_pubchem_ids:
                results.unmatched_bigg_id(bigg_id)
                continue

            if len(mnx_pubchem_ids) == 1:

                mnx_pubchem_id = mnx_pubchem_ids[0]

                if scraped_pubchem_id:
                    if scraped_pubchem_id == mnx_pubchem_id:
                        results.matched_pubchem_id(bigg_id, scraped_pubchem_id, mnx_pubchem_id)
                    else:
                        results.conflicted_pubchem_id(bigg_id, scraped_pubchem_id, mnx_pubchem_id)
                else:
                    metabolite[PUBCHEM_ID] = mnx_pubchem_id
                    results.added_pubchem_id(bigg_id, mnx_pubchem_id)

            else:

                if scraped_pubchem_id:
                    if scraped_pubchem_id in mnx_pubchem_ids:
                        results.confirmed_pubchem_id(bigg_id, scraped_pubchem_id, mnx_pubchem_ids)
                    else:
                        results.conflicted_pubchem_id(bigg_id, scraped_pubchem_id, mnx_pubchem_ids)
                else:
                    added = mnx_pubchem_ids[0]
                    metabolite[PUBCHEM_ID] = added
                    results.added_arbirtrary_id(bigg_id, added, mnx_pubchem_ids)

    results.log()

    # TODO: rewrite the file


if __name__ == '__main__' or __name__ == 'jbei.edd.scripts.update_metabolites':
    result = main()
    exit(result)
