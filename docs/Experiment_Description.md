#Experiment Description Back End - Technical Documentation

## Context

The initial versions of this code supports only the Experiment Description (ED) file upload GUI, 
but the back end is designed to handle both the immediate need to process 
Experiment Description files and the planned GUI for combinatorial line creation. As a result, the 
code is fairly 
abstract, and there are many Python classes and functions involved in making a single code path 
support both JSON and Excel input use cases. UML class diagrams of the `edd.main.importer
.utilities` and `.parsers` modules can be a good place to start, though some class relationships
span those modules in the current code.

For those with access to JBEI's ticketing system, see the following tickets and related Pull 
Requests for other good entry points into the development of this code:

* [EDD-514][1]: Back end support for experiment description file upload
* [EDD-603][2]: Polish advanced Experiment Description back-end features

## Features

* **Support for multiple input formats**: the back end supports both Experiment Description file 
  uploads, as well as JSON input planned for the combinatorial line creation GUI ([EDD-257][3]).
   For sample JSON, see unit test code in [main.tests.utilities.py](../main/tests/utilities.py)
* **Configurable, automated naming**: depending on which input path is used, the back end
  supports multiple types of configurable, potentially automated line and assay naming. Automated
  naming options are limited by the format of Experiment Description files, while JSON input is
  written to support fully-configurable name formatting.  See the [File format housekeeping][4] and
  [Combinatorial Line Creation][5] sections of the experiment description help for a 
  summary of automated naming options available in Experiment Description files. JSON input written
  to support the combinatorial line creation GUI includes fully-customizable naming, including 
  custom user additions to the names, use of abbreviations, etc.  For examples of JSON options,
  see the associated unit tests in `main.tests.utilities` that test the scenario displayed in
  the combinatorial line creation GUI mockup attached to [EDD-257][3].
* **Dry run**: the back end supports a `DRY_RUN` URL parameter that causes it to compute line/assay 
  names and perform the majority of related error checks without actually changing the study. This 
  feature supports consistently computing & displaying the line & assay name previews assumed in 
  the combinatorial line creation GUI mockups attached to [EDD-257][3].
* **Duplicate name detection**: the back end supports detecting duplicated line/assay names 
  generated by the input (self-inconsistent input), as well as detection of new line/assay
  names that would duplicate lines/assays that already in the study.
* **ICE-related error handling**: user errors often manifest during ICE queries to resolve input 
  part ids to the EDD strains that match them.  There's support for detecting and aggregating 
  errors related to parts not contained in ICE, for ICE permission errors, and for detecting and 
  notifying administrators of problems that occurred while attempting to communicate with ICE.
* **Problem workarounds**: in the event of ICE-related errors (whether or not they're caused by 
  user error), the ED back-end supports ignoring ICE-related problems when needed as a workaround.
   It also supports allowing researchers to purposefully create duplicate line/assay names, if 
   needed. Clients can use these workarounds by passing any value to the 
   `IGNORE_ICE_RELATED_ERRORS` or `ALLOW_DUPLICATE_NAMES` parameters, respectively.
* **Error categorization and prioritization**: the back end categorizes and prioritizes errors 
  and warnings returned to clients.  User-resolvable problems bubble to the top so that problems
  caused by the user can be resolved, particularly those that may have caused follow-on errors.
  

## Steps in the Process

Since there's a lot of code involved in making the Experiment Description upload work, plus a need 
for some additional style improvements to the code, it can be difficult/time-consuming to 
extrapolate an overview of the processing from looking at the code.  This section contains an 
overview of the steps involved in processing Experiment Description files, as well as some of the 
motivations for the current design.

### Motivation
Each stage of the upload is performed separately, and errors/warnings from each is typically
aggregated and returned to the user all at once. Note that we could potentially combine / 
rearrange some of the steps later for improved ease-of-use, but initial considerations were: 
1. **Satisfy required preconditions for each step**

   The current code structure takes multiple use-cases into account, and can be easy
   to make bad inferences about from the simpler example files. For instance, although the 
   dependency won't appear in every ED file, strain IDs from ICE have to be resolved before 
   attempting to compute line/assay names that could depend on them.
2. **Allow the process to abort early at logical stages.**

   For example, give responsive feedback on file format errors before performing 
   potentially-expensive I/O that may not be informative following the initial input problems.
3. **Aggregate errors** (especially user errors)

   At each stage in the process, detect and aggregate related errors and to give feedback on them 
   all at once. The intent is to support an efficient / usable user interface.
4. **Defer I/O until as late as possible**

   Following some initial context lookup required to inform file parsing, API 
   communication with ICE and final communication with with EDD's database are reserved until as 
   late as possible in the process.  For example, no database queries are performed during the 
   initial planning stage when line/assay names in resulting from user input are first determined 
   and checked against each other for self-consistency.  This should help keep the dry run feature 
   responsive and keep error feedback responsive for inconsistent user input, though at a 
   reasonable efficiency cost for successful executions.
5. **Implement / Field Test Simple Processing Before Adding Complexity**

   Though some thought was given to using paralellism and asynchronous request processing, 
   developing and testing a synchronous, single-threaded version of the code should be simpler and
   more time-efficient than prematurely optimizing.
   
### Processing Steps

1. **Initial context queries**
   Check/enforce study write
   permissions before doing any other processing. Get metadata types, units, etc from EDD's 
   database to inform input parsing.
2. **Input parsing**
   We attempt to detect as many errors as possible up-front during file parsing, but at the time
   of writing, there's little-to-no checking on line/assay metadata values users enter.  This step 
   will be impacted by plans for [EDD-438][5] and related tickets.
3. **ICE strain lookup**
   Use part ids from user input to locate strains in ICE.  To prevent fragmentation and avoid
   problems related to non-uniqueness of part numbers across ICE instances, EDD has to perform this
   lookup each time, even for parts previously used in EDD studies. Though they can be non-unique,
   part ID's are succinct and human-readable, which is why they're used in the input.
   Main sources of error in this stage should be data entry and communication errors when 
   attempting to access individual ICE parts, or having permission to access them, are aggregated 
   as much as possible. More basic communication errors (e.g. inability to connect) will abort the 
   entire process.
4. **Manage strains cached by EDD**
   For strains located in ICE, look for cached entries in EDD's database.  For those that don't 
   exist already, create an entry, even if subsequent processing fails. New strain entries are 
   likely to be needed once other problems in the input have been resolved.
5. **Compute line and assay names**
   With strains resolved, compute planned names for the new lines and assays, which depending on
   input, may include strain names.
6. **Early Bail out opportunity for dry run** , e.g. to compute line/assay names for display
   while work is underway in a GUI, but without making any actual changes.
7. **Perform final consistency checks**
   First check for duplicate new line/assay names that will be created by the input, then check
   planned line/assay names against preexisting lines/assays in the study.
8. **Update the study**
   Using the same code path used to compute planned line/assay names earlier in the process,
   re-compute the names as part of creating the objects in the database.

## Testing

It's nearly impossible to test all the possible combinations of input for Experiment Descriptions,
but we should make an effort to test at least some common variations.  It's a good idea to 
aggregate changes to this code before retesting, since at present even testing a decent subset of possible 
inputs takes a lot of manual effort.  Suggested / semi-comprehensive test procedure for this code involves:

1. Run the unit tests.  
   At the time of writing, these can only cover *some* of the most highly-trafficed code path. 
   Once we have CI and time for additional work on this, ICE integration and error handling can / 
   should be automatically tested.
   
       docker-compose exec edd python /code/manage.py test main.tests.utilities
	
2. Test the sample file AND example files referenced from figures in the Experiment Description 
   help.  
   Figure captions in the help have links for downloading the files, or you can find them under 
   `main/static/experiment_description`.
   
3. Test the sample test inputs in the Google Drive folder.  
   There's some overlap between these and the examples from the help, but these files tend to cover 
   more error cases and more complex examples that didn't make sense to include in training 
   material.

4. Uncomment & run ICE communication error scenarios documented / manually testable in 
   `main.importer.experiment_desc.py`.  Follow-on work should eventually unit test these scenarios, 
   but manual test procedures captured here were an efficient way to experiment with and initially 
   test these error scenarios.

## Future Work / Known Gaps

The current Experiment Description upload process is itself a workaround pending bandwidth to work
on one ore more full-featured user interfaces for line creation ([EDD-257][3]). Users have to 
manually look up valid column headers, and cell contents are generally not validated (see 
[EDD-438][5]).

There are some known / manageable gaps in the code planned to support the combinatorial GUI, but
work to date on that code should have mitigated most of the major risks. See [EDD-626][8] for 
follow-on back-end work to support the combinatorial line creation GUI.

There's also some additional polishing needed in the current back-end code ([EDD-760][7]), but no 
known issues that should hold up the 2.0.4 release.

[1]:    https://support.jbei.org/browse/EDD-514
[2]:    https://support.jbei.org/browse/EDD-603
[3]:    https://support.jbei.org/browse/EDD-257
[4]:    http://edd.jbei.org/help/experiment_description/#housekeeping
[5]:    http://edd.jbei.org/help/experiment_description/#combinatorial_line
[6]:    https://support.jbei.org/browse/EDD-438
[7]:    https://support.jbei.org/browse/EDD-760
[8]:    https://support.jbei.org/browse/EDD-628